% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/station_batch.R
\name{station_batch}
\alias{station_batch}
\title{Download multiple station time series and parameters at once}
\usage{
station_batch(
  resource_id,
  parameters,
  station_ids,
  path_dir_save,
  date_start,
  date_end,
  save_extra = FALSE,
  show_progress = TRUE
)
}
\arguments{
\item{resource_id}{The resource_id as available in
\code{\link{datasets_zamg}}.}

\item{parameters}{Parameters (character), might have different name depending
on resource_id, see also \code{\link{metadata_station}}.}

\item{station_ids}{Station identifiers (character), see also
\code{\link{metadata_station}}. If omitted, will take all available
stations for the resource_id.}

\item{path_dir_save}{Directory folder to save files.}

\item{date_start}{The start date (ISO8601) to download the time series. If
missing, starting date will be extracted from internal metadata.}

\item{date_end}{The end date (ISO8601) to download the time series. Default:
current system time.}

\item{save_extra}{Logical, if TRUE, saves combined data with auxiliary info.}

\item{show_progress}{Logical, if TRUE, shows progress bar.}
}
\value{
The directory path as character string. Saves files along the way.
}
\description{
Wrapper around \code{\link{station_single}}, with some extra functionality.
Will download all parameters and all stations specified, and save them in the
given directory. Start and end date can be omitted, in which case the whole
time series up to the current time will be downloaded.
}
\details{
Creates a folder for each parameter within path_dir_save, and saves the
downloaded tables as rds-files that have the station id as filename. If the
file already exists, it will be skipped (so it can be downloaded in multiple
sessions).

If save_extra is TRUE, then the downloaded single series will be combined
into one tibble storing all stations and parameters. Additionally, tibbles
will be save with information on parameters and stations, which are subsets
of \code{\link{metadata_station}}. In summary, the resulting files allow fast
working with the data.
}
\examples{

\dontrun{
library(dplyr)

# which snow parameters are there for monthly data?
metadata_station$`klima-v1-1m`$parameters \%>\%
    filter(grepl("schnee", long_name, ignore.case = TRUE))

# take monthly cumulative snowfall and maximum snow height
params <- c("nsch", "schmax")

# subset stations above 2000m and with data starting before 1920
stn_ids <- metadata_station$`klima-v1-1m`$stations \%>\%
    filter(altitude > 2000, valid_from < "1920-01-01") \%>\%
    pull(id)

# path to save
path_dir_save <- tempdir() # temporary directory for examples

# download whole time series
station_batch(resource_id = "klima-v1-1m",
              parameters = params,
              station_ids = stn_ids,
              path_dir_save = path_dir_save)
}
}
