% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batch_download.R
\name{batch_download}
\alias{batch_download}
\title{Download multiple time series and parameters at once}
\usage{
batch_download(
  resource_id,
  parameters,
  station_ids,
  path_dir_save,
  date_start,
  date_end = lubridate::format_ISO8601(Sys.time()),
  save_extra = FALSE,
  show_progress = TRUE,
  type = "station",
  mode = "historical"
)
}
\arguments{
\item{resource_id}{The resource_id as available in \code{\link{datasets_zamg}}.}

\item{parameters}{Parameters (character), might have different name depending on resource_id,
see also \code{\link{metadata_zamg}}.}

\item{station_ids}{Station identifiers (character), see also \code{\link{metadata_zamg}}.}

\item{path_dir_save}{Directory folder to save files.}

\item{date_start}{The start date (ISO8601) to download the time series. If missing,
starting date will be extracted from internal metadata.}

\item{date_end}{The end date (ISO8601) to download the time series. Default: current
system time.}

\item{save_extra}{Logical, if TRUE, saves combined data with auxiliary info.}

\item{show_progress}{Logical, if TRUE, shows progress bar.}

\item{type}{Data type, currently, pkg is only tested with "station" (default).}

\item{mode}{Data mode, currently, pkg is only tested with "historical" (default).}
}
\value{
Invisible: the directory as character string. Saves files along the way.
}
\description{
Wrapper around \code{\link{single_series}}, with some extra functionality.
Will download all parameters and all station specified, and save them in
the given directory. Start and end date can be omitted, in which case the
whole time series up to the current time will be downloaded.
}
\details{
Creates a folder for each parameter within path_dir_save, and saves the
downloaded tables as rds-files that have the station id as filename. If
the file already exists, it will be skipped (so it can be downloaded in
multiple sessions).

If save_extra is TRUE, then the downloaded single series will be combined
into one tibble storing all stations and parameters. Additionally, tibbles
will be save with information on parameters and stations, which are subsets
of \code{\link{metadata_zamg}}. In summary, the resulting files allow fast
working with the data.
}
\examples{

# which snow parameters are there for monthly data?
metadata_zamg$`klima-v1-1m`$parameters \%>\%
    dplyr::filter(grepl("schnee", long_name, ignore.case = T))

# take monthly cumulative snowfall and maximum snow height
params <- c("nsch", "schmax")

# subset stations above 2000m and with data starting before 1920
stn_ids <- metadata_zamg$`klima-v1-1m`$stations \%>\%
    dplyr::filter(altitude > 2000, valid_from < "1920-01-01") \%>\%
    dplyr::pull(id)

# path to save
path_dir_save <- tempdir() # temporary directory for examples

# download whole time series
batch_download(id = "klima-v1-1m",
               parameters = param,
               station_ids = stn_ids,
               path_dir_save = path_dir_save)


}
